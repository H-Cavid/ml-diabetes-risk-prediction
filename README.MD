# ğŸ§  Diabetes Risk Prediction â€“ TÆBÄ°B Monitoring Initiative

This project presents a machine learning pipeline for predicting diabetes risk based on clinical and demographic data. Developed as part of a machine learning module at FH Kiel, the project simulates a real-world healthcare initiative (TÆBÄ°B Diabetes Monitoring) and applies predictive modeling techniques such as Decision Trees and K-Nearest Neighbors. The aim is to support early detection and efficient screening in public health systems. The project demonstrates end-to-end skills including data cleaning, exploratory data analysis (EDA), feature engineering, model selection, hyperparameter tuning, and interpretability via feature importance.

---

## ğŸ” Objectives

- Predict diabetes risk using clinical data  
- Analyze feature importance (HbA1c, glucose, age, etc.)  
- Evaluate classification models using nested cross-validation  
- Support early detection and healthcare resource allocation for TÆBÄ°B

---

## ğŸ“Š Dataset

- Source: [Kaggle â€“ Diabetes Prediction Dataset](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset)  
- 100,000 rows, 9 clinical features  
- Target: `diabetes` (1 = diabetic, 0 = non-diabetic)

---

## ğŸ› ï¸ Technologies Used

- Python , Jupyter Notebook  
- `pandas`, `numpy` â€“ data handling  
- `matplotlib`, `seaborn`, `plotly` â€“ visualization  
- `scikit-learn` â€“ ML models (Decision Tree, KNN), preprocessing, evaluation  
- **GridSearchCV**, **Nested Cross-Validation** â€“ model tuning & validation  
- **Permutation Importance** â€“ model interpretability  
- **StandardScaler**, one-hot encoding â€“ feature scaling & engineering

---

## ğŸ”§ Techniques Used

- Exploratory Data Analysis (EDA)  
- Outlier detection and data cleaning  
- One-hot encoding and feature engineering  
- Decision Tree, KNN, Dummy Classifier  
- GridSearchCV and Nested Cross-Validation  
- Permutation Importance  
- Confusion Matrix & Classification Reports

---

## ğŸ—‚ï¸ Project Structure

```
ml-diabetes-risk-prediction/
â”œâ”€â”€ data/ # (optional) input data files
â”œâ”€â”€ notebooks/ # Jupyter notebook: experiments.ipynb
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project overview and instructions
â”œâ”€â”€ .gitignore # Ignored files
â””â”€â”€ env/ # Virtual environment (not pushed)
```


---

## ğŸ“ˆ Visualizations

- Histograms and boxplots of age, BMI, HbA1c, glucose  
- 3D scatter plot of Age vs BMI vs HbA1c  
- Feature-target relationship plots (bar, line, density)  
- Correlation heatmap  
- Permutation-based feature importance  
- Confusion matrix heatmap

---

## ğŸ“„ Results

- Final model: **Decision Tree**, tuned with GridSearchCV  
- Validated with nested cross-validation  
- Most predictive features: `HbA1c_level`, `blood_glucose_level`

| Metric       | Score     |
|--------------|-----------|
| Accuracy     | 97.08%    |
| Precision    | 97.08%    |
| Recall       | 97.08%    |
| F1 Score     | 96.86%    |

---

## â–¶ï¸ How to Run

```bash
# Clone the repo
git clone https://github.com/your-username/ml-diabetes-risk-prediction.git
cd ml-diabetes-risk-prediction

# Create virtual environment
python -m venv env
source env/bin/activate  # Or use `env\Scripts\activate` on Windows

# Install required libraries
pip install -r requirements.txt

# Open the notebook
jupyter notebook notebooks/experiments.ipynb
```
---

## ğŸ“œ License

This project is licensed under **CC BY-NC-ND 4.0**.

- You **can** view and share the project with proper credit.  
- You **cannot** use it for commercial purposes or modify/reuse it as your own.

---

## ğŸ‘¤ Author

**Javid Hasanov**  
Master's student in Data Science at FH Kiel
  
[LinkedIn](https://www.linkedin.com/in/javidhasanov-tech/) â€¢ [GitHub](https://github.com/H-Cavid)

